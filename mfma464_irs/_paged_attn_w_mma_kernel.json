{"hash": "bac9216016c657f1d378687e75b540b8ff74f4b3cecd8fd5d18e0a79aef6853a", "target": {"backend": "hip", "arch": "gfx942", "warp_size": 64}, "num_warps": 2, "waves_per_eu": 1, "num_stages": 1, "num_ctas": 1, "extern_libs": [["ocml", "/triton/python/triton/backends/amd/lib/ocml.bc"], ["ockl", "/triton/python/triton/backends/amd/lib/ockl.bc"]], "cluster_dims": [1, 1, 1], "debug": false, "sanitize_overflow": true, "arch": "gfx942", "supported_fp8_dtypes": ["fp8e4b8", "fp8e5", "fp8e5b16"], "deprecated_fp8_dtypes": [], "default_dot_input_precision": "ieee", "allowed_dot_input_precisions": ["ieee"], "enable_fp_fusion": true, "matrix_instr_nonkdim": 464, "kpack": 1, "allow_flush_denorm": false, "max_num_imprecise_acc_default": 0, "backend_name": "hip", "instruction_sched_variant": "default", "warp_size": 64, "shared": 16384, "name": "_paged_attn_w_mma_kernel"}